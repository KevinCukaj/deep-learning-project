@inproceedings{fma_dataset,
  title = {{FMA}: A Dataset for Music Analysis},
  author = {Defferrard, Micha\"el and Benzi, Kirell and Vandergheynst, Pierre and Bresson, Xavier},
  booktitle = {18th International Society for Music Information Retrieval Conference (ISMIR)},
  year = {2017},
  archiveprefix = {arXiv},
  eprint = {1612.01840},
  url = {https://arxiv.org/abs/1612.01840},
}

@inproceedings{liu2024audiosr,
  title={{AudioSR}: Versatile audio super-resolution at scale},
  author={Liu, Haohe and Chen, Ke and Tian, Qiao and Wang, Wenwu and Plumbley, Mark D},
  booktitle={IEEE International Conference on Acoustics, Speech and Signal Processing},
  pages={1076--1080},
  year={2024},
  organization={IEEE}
}

@article{han2022nu,
  title={NU-Wave 2: A General Neural Audio Upsampling Model for Various Sampling Rates},
  author={Han, Seungu and Lee, Junhyeok},
  journal={arXiv preprint arXiv:2206.08545},
  year={2022}
}

@article{NOGALES2023120586,
  title = {A deep learning framework for audio restoration using Convolutional/Deconvolutional Deep Autoencoders},
  journal = {Expert Systems with Applications},
  volume = {230},
  pages = {120586},
  year = {2023},
  issn = {0957-4174},
  doi = {https://doi.org/10.1016/j.eswa.2023.120586},
  url = {https://www.sciencedirect.com/science/article/pii/S0957417423010886},
  author = {Alberto Nogales and Santiago Donaher and Álvaro García-Tejedor},
  keywords = {Signal processing, Deep learning, Convolution, Autoencoders, Audio restoration},
  abstract = {People communicate daily with their mobile phones and in some cases, the quality of the communication may be vital. Thus, there is a clear interest in improving the quality of communication in cases of low signal or interferences. This paper shows how deep learning techniques are used to restore audio files that simulate situations of background noise and loss of signal. Its main distinguishing feature is the direct use of the waveform instead of a spectrogram representation which lets the model be adapted to real-time communications or broadcasting. The results show that our proposal improves performance compared to Wave-U-Net. After restoring the audio, the difference between the original and the restored audio is, on average, less than 2%. In addition, a subjective test was carried out with 113 people who detected a significant improvement in the restored audio compared to the damaged one.}
}

@misc{lemercier2024diffusionmodelsaudiorestoration,
  title={Diffusion Models for Audio Restoration}, 
  author={Jean-Marie Lemercier and Julius Richter and Simon Welker and Eloi Moliner and Vesa Välimäki and Timo Gerkmann},
  year={2024},
  eprint={2402.09821},
  archivePrefix={arXiv},
  primaryClass={eess.AS},
  url={https://arxiv.org/abs/2402.09821}, 
}

@inproceedings{rouard2022hybrid,
  title={Hybrid Transformers for Music Source Separation},
  author={Rouard, Simon and Massa, Francisco and D{\'e}fossez, Alexandre},
  booktitle={ICASSP 23},
  year={2023}
} 